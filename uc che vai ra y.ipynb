{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import data\n",
    "import utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.load()\n",
    "hyper_params = {\n",
    "    'kernels_width': [3000, 1500, 750],\n",
    "    'channels_out': [5, 10, 20],\n",
    "    'strides': [300, 150, 75],\n",
    "    'num_hiddens_rnn': [200, 200],\n",
    "    'num_classes': 28,\n",
    "    'learning_rate': 1e-2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph(hyper_params=hyper_params):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "        with tf.name_scope('input') as scope:\n",
    "            X = tf.placeholder(tf.float32, [None, None, 1], name='input_x') \n",
    "            Y = tf.sparse_placeholder(tf.int32, name='input_y')\n",
    "            seq_len = tf.placeholder(tf.float32, [None], name='seq_len')\n",
    "\n",
    "        with tf.name_scope('batch_size') as scope:\n",
    "            shape = tf.shape(X)\n",
    "            batch_size = shape[0]\n",
    "\n",
    "        out = X\n",
    "        last_channel_out = 1 \n",
    "        out_seq_len = seq_len\n",
    "        \n",
    "        for i in range(len(hyper_params['kernels_width'])):\n",
    "            with tf.name_scope('conv%d' % i) as scope:\n",
    "                kernel = tf.get_variable('conv_kernel%d' % i, \n",
    "                    [hyper_params['kernels_width'][i], last_channel_out, hyper_params['channels_out'][i]], \n",
    "                    initializer=tf.truncated_normal_initializer())\n",
    "                biases = tf.get_variable('conv_biases%d' % i, \n",
    "                    [hyper_params['channels_out'][i]], \n",
    "                    initializer=tf.random_normal_initializer())        \n",
    "                out = tf.nn.conv1d(out, kernel, stride=hyper_params['strides'][i], padding='SAME')\n",
    "                out = tf.nn.relu(out + biases, name='conv%d' % i)\n",
    "                last_channel_out = hyper_params['channels_out'][i]\n",
    "                \n",
    "                out_seq_len = tf.ceil(out_seq_len / hyper_params['strides'][i])\n",
    "\n",
    "        with tf.name_scope('rnn') as scope:\n",
    "            cells = []\n",
    "            for num_hidden in hyper_params['num_hiddens_rnn']:\n",
    "                cell = tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "                cells.append(cell)\n",
    "            stack = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "            out, _ = tf.nn.dynamic_rnn(stack, out, out_seq_len, dtype=tf.float32)\n",
    "\n",
    "        with tf.name_scope('fc') as scope:\n",
    "            last_hidden = hyper_params['num_hiddens_rnn'][len(hyper_params['num_hiddens_rnn']) - 1]\n",
    "            out = tf.reshape(out, [-1, last_hidden])\n",
    "            W = tf.Variable(tf.truncated_normal([last_hidden, hyper_params['num_classes']],stddev=0.1, name='fc_w%d' % i))\n",
    "            b = tf.Variable(tf.constant(0., shape=[hyper_params['num_classes']], name='fc_b%d' % i))\n",
    "            logits = tf.nn.xw_plus_b(out, W, b)\n",
    "\n",
    "        with tf.name_scope('ctc_loss_function') as scope:\n",
    "            logits = tf.reshape(logits, [batch_size, -1, hyper_params['num_classes']])\n",
    "            logits = tf.transpose(logits, (1, 0, 2))\n",
    "            out_seq_len = tf.cast(out_seq_len, tf.int32)\n",
    "            loss = tf.nn.ctc_loss(Y, logits, out_seq_len)\n",
    "            cost = tf.reduce_mean(loss)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(hyper_params['learning_rate']).minimize(cost, global_step=global_step)\n",
    "\n",
    "        with tf.name_scope('decoding') as scope:\n",
    "            decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, out_seq_len)\n",
    "            ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),Y))\n",
    "\n",
    "        with tf.name_scope('loss_by_step') as scope:\n",
    "            tf.summary.scalar('cost', cost)\n",
    "            tf.summary.scalar('ler', ler)\n",
    "            summary_op = tf.summary.merge_all()\n",
    "    model_vars = {\n",
    "        'X': X, 'Y': Y, 'seq_len': seq_len, 'global_step': global_step, \n",
    "        'ler': ler, 'summary_op': summary_op, 'optimizer': optimizer, 'decoded': decoded, 'cost': cost,\n",
    "        'logits': logits, 'log_prob': log_prob,\n",
    "        'out_seq_len': out_seq_len\n",
    "    }\n",
    "    return graph, model_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph, model_vars = create_graph(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train 240 num_test 60 n_batch 1200000000 batch_per_epochs 120\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "label SparseTensor is not valid: indices[1] = [0,1] is out of bounds: need 0 <= index < [2,1]\n\t [[Node: ctc_loss_function/CTCLoss = CTCLoss[ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false, preprocess_collapse_repeated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ctc_loss_function/transpose/_45, _arg_input/input_y/indices_0_1, _arg_input/input_y/values_0_3, ctc_loss_function/Cast/_47)]]\n\nCaused by op 'ctc_loss_function/CTCLoss', defined at:\n  File \"C:\\Users\\root\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-4c0eefccc44f>\", line 2, in <module>\n    graph, model_vars = create_graph(hyper_params)\n  File \"<ipython-input-3-104917a899c8>\", line 55, in create_graph\n    loss = tf.nn.ctc_loss(Y, logits, out_seq_len)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ctc_ops.py\", line 152, in ctc_loss\n    ignore_longer_outputs_than_inputs=ignore_longer_outputs_than_inputs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_ctc_ops.py\", line 170, in _ctc_loss\n    name=name)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): label SparseTensor is not valid: indices[1] = [0,1] is out of bounds: need 0 <= index < [2,1]\n\t [[Node: ctc_loss_function/CTCLoss = CTCLoss[ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false, preprocess_collapse_repeated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ctc_loss_function/transpose/_45, _arg_input/input_y/indices_0_1, _arg_input/input_y/values_0_3, ctc_loss_function/Cast/_47)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: label SparseTensor is not valid: indices[1] = [0,1] is out of bounds: need 0 <= index < [2,1]\n\t [[Node: ctc_loss_function/CTCLoss = CTCLoss[ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false, preprocess_collapse_repeated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ctc_loss_function/transpose/_45, _arg_input/input_y/indices_0_1, _arg_input/input_y/values_0_3, ctc_loss_function/Cast/_47)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-66d3e7f13ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                       \u001b[0mmodel_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                                       \u001b[0mmodel_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ler'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                                       model_vars['summary_op']], feed)\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: label SparseTensor is not valid: indices[1] = [0,1] is out of bounds: need 0 <= index < [2,1]\n\t [[Node: ctc_loss_function/CTCLoss = CTCLoss[ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false, preprocess_collapse_repeated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ctc_loss_function/transpose/_45, _arg_input/input_y/indices_0_1, _arg_input/input_y/values_0_3, ctc_loss_function/Cast/_47)]]\n\nCaused by op 'ctc_loss_function/CTCLoss', defined at:\n  File \"C:\\Users\\root\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-4c0eefccc44f>\", line 2, in <module>\n    graph, model_vars = create_graph(hyper_params)\n  File \"<ipython-input-3-104917a899c8>\", line 55, in create_graph\n    loss = tf.nn.ctc_loss(Y, logits, out_seq_len)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\ctc_ops.py\", line 152, in ctc_loss\n    ignore_longer_outputs_than_inputs=ignore_longer_outputs_than_inputs)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_ctc_ops.py\", line 170, in _ctc_loss\n    name=name)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\root\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): label SparseTensor is not valid: indices[1] = [0,1] is out of bounds: need 0 <= index < [2,1]\n\t [[Node: ctc_loss_function/CTCLoss = CTCLoss[ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false, preprocess_collapse_repeated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ctc_loss_function/transpose/_45, _arg_input/input_y/indices_0_1, _arg_input/input_y/values_0_3, ctc_loss_function/Cast/_47)]]\n"
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'batch_size' : 2,\n",
    "    'skip_step' : 4,\n",
    "    'n_epochs' : 10000000\n",
    "}\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Mot vai thu tuc\n",
    "    tf.global_variables_initializer().run()\n",
    "    writer = tf.summary.FileWriter('./graphs/', sess.graph)\n",
    "    saver = tf.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state('./checkpoints/')\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    # Mot vai variable\n",
    "    initial_step = model_vars['global_step'].eval()\n",
    "    num_train, num_test = data.stats()\n",
    "    print('num_train', num_train, \n",
    "          'num_test', num_test, \n",
    "          'n_batch',int(train_params['n_epochs'] * num_train/train_params['batch_size']), \n",
    "          'batch_per_epochs', int(num_train/train_params['batch_size']))\n",
    "    train_batch = data.train_batch_generator(train_params['batch_size'])\n",
    "\n",
    "    # Training\n",
    "    for i in range(initial_step,  int(train_params['n_epochs'] * num_train/train_params['batch_size'])):\n",
    "        X_batch, seq_len_batch, Y_batch = next(train_batch)\n",
    "        feed = {model_vars['X']: X_batch,\n",
    "            model_vars['Y']: Y_batch,\n",
    "            model_vars['seq_len']: seq_len_batch}\n",
    "        batch_cost, _, batch_ler, summary = sess.run([model_vars['cost'], \n",
    "                                                      model_vars['optimizer'], \n",
    "                                                      model_vars['ler'], \n",
    "                                                      model_vars['summary_op']], feed)\n",
    "        writer.add_summary(summary, global_step=i)\n",
    "\n",
    "        if i % train_params['skip_step'] == 0:\n",
    "            print('batch', i, 'cost', batch_cost, 'ler', batch_ler)\n",
    "            saver.save(sess, './checkpoints/', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size' : 2,\n",
    "    'skip_step' : 1,\n",
    "    'n_epochs' : 10000000\n",
    "}\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    X_batch, seq_len_batch, Y_batch = next(train_batch)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
